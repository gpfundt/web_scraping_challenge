{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import bs4\n",
    "import urllib.parse\n",
    "import pymongo\n",
    "from splinter import Browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define urls\n",
    "url = 'https://mars.nasa.gov/news/'\n",
    "url2 = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "url3 = 'https://twitter.com/marswxreport?lang=en'\n",
    "url4 = 'https://space-facts.com/mars/'\n",
    "url5 = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "#set up chromedriver and launch \n",
    "executable_path={'executable_path':'chromedriver'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#send the open browser to the first nasa url\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the soup\n",
    "soup = bs4.BeautifulSoup(browser.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find a section with the headlines from the soup\n",
    "headlines_and_more = soup.find_all(class_= 'content_title', limit=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get just the headline text for each of the headlines \n",
    "headlines_and = []\n",
    "\n",
    "for headline in headlines_and_more:\n",
    "    headlines_and.append(headline.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "headlines_and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean the headlines\n",
    "headlines = []\n",
    "\n",
    "for h in headlines_and:\n",
    "    h = h.replace('\\n','')\n",
    "    headlines.append(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the actual news title from the headlines\n",
    "news_title = headlines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the summary info from the soup\n",
    "info_and_more = soup.find_all(class_= 'article_teaser_body', limit=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get just the info summary for each of the summaries\n",
    "info_and = []\n",
    "\n",
    "for info in info_and_more:\n",
    "    info_and.append(info.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean the info\n",
    "info = []\n",
    "\n",
    "for i in info_and:\n",
    "    i = i.replace('\\n','')\n",
    "    info.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the actual news paragraph for each\n",
    "news_p = info[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#send the browser to the second url\n",
    "browser.visit(url2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the soup for this url\n",
    "soup2 = bs4.BeautifulSoup(browser.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#have chrome driver go to the image by clicking the FULL IMAGE button\n",
    "browser.click_link_by_partial_text('FULL IMAGE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the div tag with the image\n",
    "img_info = soup2.find('div', {'class': 'img'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#isolate the actual image url from the div tag\n",
    "img_url = img_info.contents[1]\n",
    "featured_img_url = img_url['src']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_img_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#have chrome driver go to the next url\n",
    "browser.visit(url3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get soup 3\n",
    "soup3 = bs4.BeautifulSoup(browser.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the container that has the actual tweets\n",
    "tweet_info = soup3.find(class_ = 'js-tweet-text-container')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#isolate the tweet from the container\n",
    "tweet = tweet_info.contents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the mars weather tweets\n",
    "mars_weather = tweet.contents[0]\n",
    "mars_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pandas read_html to find the table in the 4th url and save it as a dataframe\n",
    "df = pd.read_html(url4)\n",
    "len(df)\n",
    "table_data = df[0]\n",
    "table_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remake the table with to_html and save under mars facts\n",
    "mars_facts = table_data.to_html()\n",
    "mars_facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#have chromedriver go to url5 and get the soup\n",
    "browser.visit(url5)\n",
    "soup5 = bs4.BeautifulSoup(browser.html)\n",
    "\n",
    "#find the 4 most recent descriptions \n",
    "descriptions = soup5.find_all(class_='description', limit = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an empty list to save the following information\n",
    "hemisphere_image_urls = []\n",
    "\n",
    "#for each of the 4 descriptions found in url5 get the header and the image url\n",
    "for desc in descriptions:\n",
    "    browser.visit(url5)\n",
    "    soup5 = bs4.BeautifulSoup(browser.html)\n",
    "    header = desc.find('h3').contents[0]\n",
    "    browser.click_link_by_partial_text(header)\n",
    "    soup6 = bs4.BeautifulSoup(browser.html)\n",
    "    img_url = soup6.find(class_='wide-image')['src']\n",
    "    hemisphere_image_urls.append({'title':header, 'img_url':img_url})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemisphere_image_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
